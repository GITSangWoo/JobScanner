from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.wait import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from datetime import datetime
from zoneinfo import ZoneInfo
import boto3
import pymysql
import random
import re
import requests
import time
import uuid

kst = ZoneInfo("Asia/Seoul")

# AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
s3 = boto3.client('s3')

# ë³€ìˆ˜ ì„¤ì • : ë§í¬ ì €ì¥ì„ ìœ„í•œ S3
BUCKET_NAME = 't2jt'
S3_LINK_PATH = 'job/{abb}/airflow_test/rocketpunch/links/'
S3_TEXT_PATH = 'job/{abb}/airflow_test/rocketpunch/txt/'
S3_IMAGE_PATH = 'job/{abb}/airflow_test/rocketpunch/images/'  

# MySQL ì—°ê²° ì„¤ì •
connection = pymysql.connect(
    host='43.201.40.223',
    user='user',
    password='1234',
    database='testdb',
    port=3306
)
cursor = connection.cursor()

# ë³€ìˆ˜ ì„¤ì • : ê²€ìƒ‰ í‚¤ì›Œë“œ
job_titles = {
    "DE":"ë°ì´í„° ì—”ì§€ë‹ˆì–´", 
    "DA":"ë°ì´í„° ë¶„ì„ê°€", 
    "FE":"í”„ë¡ íŠ¸ì—”ë“œ ì—”ì§€ë‹ˆì–´", 
    "BE":"ë°±ì—”ë“œ ì—”ì§€ë‹ˆì–´", 
    "MLE":"ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´"
}

# User-Agent ë¬¸ìì—´
user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36"

chrome_options = Options()
chrome_options.add_argument(f"user-agent={user_agent}")
chrome_options.add_argument("--headless")  # Headless ëª¨ë“œ
chrome_options.add_argument("--disable-gpu")  # GPU ë¹„í™œì„±í™”
chrome_options.add_argument("--no-sandbox")  # ë¦¬ì†ŒìŠ¤ ì œì•½ ì—†ëŠ” í™˜ê²½ì—ì„œ ì‹¤í–‰

# Selenium ì›¹ ë“œë¼ì´ë²„ ì„¤ì •
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

# í˜ì´ì§€ í¬ë¡¤ë§ í•¨ìˆ˜
def get_job_posts(link, job_title, s3_text_path, s3_image_path):
    try:
        # ë§í¬ì—ì„œ í…ìŠ¤íŠ¸ í¬ë¡¤ë§
        print(f"í•´ë‹¹ ë§í¬: {link}ì—ì„œ ì±„ìš©ê³µê³  ìƒì„¸ í¬ë¡¤ë§ ì§„í–‰ì¤‘")
        driver.get(link)
        time.sleep(random.uniform(1, 2))  # í˜ì´ì§€ ë¡œë”© 1 ~ 2ì´ˆ ëŒ€ê¸°

        # ìŠ¤í¬ë¡¤ ë‚´ë ¤ì„œ ë¡œê·¸ì¸ íŒì—… ëœ¨ë„ë¡ ì„¤ì •
        previous_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            # ìŠ¤í¬ë¡¤ì„ ì¼ì • ê°„ê²©ìœ¼ë¡œ ë‚´ë¦¬ê¸°
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            # ìƒˆë¡œìš´ í˜ì´ì§€ ë†’ì´ë¥¼ ê°€ì ¸ì˜¤ê¸°
            new_height = driver.execute_script("return document.body.scrollHeight")
            # ì´ì „ ë†’ì´ì™€ ìƒˆ ë†’ì´ê°€ ê°™ìœ¼ë©´ ë” ì´ìƒ ìŠ¤í¬ë¡¤í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ ì¢…ë£Œ
            if new_height == previous_height:
                break
            previous_height = new_height  # ì´ì „ ë†’ì´ ì—…ë°ì´íŠ¸

        # ë¡œê·¸ì¸ íŒì—…ì°½ ë‹«ê¸° ë²„íŠ¼ í´ë¦­
        try:
            close_popup_button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, '/html/body/div[13]/div/i'))
            )
            close_popup_button.click()
            #print("íŒì—…ì°½ ë‹«ê¸° ë²„íŠ¼ í´ë¦­ ì„±ê³µ")
        except Exception as e:
            print("íŒì—…ì°½ì´ ì—†ê±°ë‚˜ ë‹«ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


        ## ë”ë³´ê¸° ë²„íŠ¼ 1
        try:
            more_button = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, '#wrap > div.eight.wide.job-content.column > section:nth-child(3) > div > a'))
            )
            actions = ActionChains(driver)
            actions.move_to_element(more_button).click().perform()
            #print("ì²«ë²ˆì§¸ ë”ë³´ê¸°ë¥¼ ê°ì§€í•˜ê³  ëˆŒë €ìŠµë‹ˆë‹¤")
        except Exception as e:
            pass

        ## ë”ë³´ê¸° ë²„íŠ¼ 2
        try:
            more_button2 = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, '#wrap > div.eight.wide.job-content.column > section:nth-child(7) > div.content.break > a'))
            )
            actions2 = ActionChains(driver)
            actions2.move_to_element(more_button2).click().perform()
            #print("ë‘ë²ˆì§¸ ë”ë³´ê¸°ë¥¼ ê°ì§€í•˜ê³  ëˆŒë €ìŠµë‹ˆë‹¤")
        except Exception as e:
            pass

        ## ë”ë³´ê¸° ë²„íŠ¼ 2.5
        try:
            more_button3 = WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, '#wrap > div.eight.wide.job-content.column > section:nth-child(7) > div > a'))
            )
            actions3 = ActionChains(driver)
            actions3.move_to_element(more_button3).click().perform()
            #print("ì„¸ë²ˆì§¸ ë”ë³´ê¸°ë¥¼ ê°ì§€í•˜ê³  ëˆŒë €ìŠµë‹ˆë‹¤")
        except Exception as e:
            pass

        # due_type, due_date í¬ë¡¤ë§ì—ì„œ ê¸ì–´ì˜¤ê¸°
        try:
            deadline_element = WebDriverWait(driver, 10).until(   
                EC.presence_of_element_located((By.CSS_SELECTOR, '#wrap > div.four.wide.job-infoset.column > div.ui.celled.grid > div:nth-child(3) > div > div:nth-child(6) > div.content'))
            )
            deadline = deadline_element.text
            if re.fullmatch(r"\d{4}-\d{2}-\d{2}", deadline):
                due_type = "ë‚ ì§œ"
                due_date = datetime.strptime(deadline, "%Y-%m-%d").strftime("%Y-%m-%d")
            else:
                # due_type = deadline
                due_type = deadline[:20] if len(deadline.encode('utf-8')) <= 20 else deadline.encode('utf-8')[:20].decode('utf-8', 'ignore')
                due_date = None
        except Exception as e:
            print("ë§ˆê° ê¸°í•œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ìš”ì†Œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤:", e)
            due_type = "unknown"
            due_date = None
        
        # íšŒì‚¬ ì´ë¦„ ìš”ì†Œ ê°ì§€
        try:
            company_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, 'nowrap.company-name'))
            )
            company_name = company_element.text
        except Exception as e:
            company_name = "unknown"
            print("íšŒì‚¬ ì´ë¦„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:", e)
        
        # ê³µê³  ì œëª© ìš”ì†Œ ê°ì§€
        try:
            post_title_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '#wrap > div.four.wide.job-infoset.column > div.ui.celled.grid > div:nth-child(3) > h2'))
            )
            post_title = post_title_element.text
        except Exception as e:
            post_title = "unknown"
            print("ê³µê³  ì œëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:", e)

        # ì—¬ê¸°ì„œ ë¶€í„° ê³µê³ ì—ì„œ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ê°ì§€ > í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ s3ì— ì €ì¥í›„ url ë°˜í™˜
        div_selectors = [
            '#wrap > div.eight.wide.job-content.column > section:nth-child(3)',   # ì£¼ìš”ì—…ë¬´
            '#wrap > div.eight.wide.job-content.column > section:nth-child(5)',   # ì—…ë¬´ê¸°ìˆ /í™œë™ë¶„ì•¼
            '#wrap > div.eight.wide.job-content.column > section:nth-child(7)',   # ì±„ìš©ìƒì„¸
            '#wrap > div.eight.wide.job-content.column > section:nth-child(11)'   # ì‚°ì—…ë¶„ì•¼
        ]  
        # process_contentì—ì„œ notice_type, text, image íƒì§€í•˜ê³  text, imageëŠ” ë°”ë¡œ s3ì— ì €ì¥
        # ê·¸ë¦¬ê³  ì €ì¥ëœ ê°ê°ì˜ s3ì˜ ì£¼ì†Œë¥¼ ë°˜í™˜
        notice_type, image_paths, text_path = process_contents(div_selectors, s3_text_path, s3_image_path)
        s3_images_url = ",".join(image_paths) if image_paths else None

        create_time = update_time = datetime.now(tz=kst).strftime("%Y-%m-%d %H:%M:%S") 
        job_post = {
            'create_time': create_time,
            'update_time': update_time,
            'removed_time': None,
            'site': 'rocketpunch',
            'job_title': job_title,  # ë™ì ìœ¼ë¡œ ë°›ì•„ì˜¨ job_title ì‚¬ìš©
            'due_type': due_type,
            'due_date': due_date,
            'company': company_name,
            'post_title': post_title,
            'notice_type': notice_type,
            'org_url': link,
            's3_text_url': text_path,
            's3_images_url': s3_images_url,
            'responsibility': None,
            'qualification': None,
            'preferential': None
        }
        
        query = """
        INSERT INTO airflowT (create_time, update_time, site, job_title, due_type, due_date, company, post_title, notice_type, org_url, s3_text_url, s3_images_url)
        VALUES (%(create_time)s, %(update_time)s, %(site)s, %(job_title)s, %(due_type)s, %(due_date)s, %(company)s, 
                %(post_title)s, %(notice_type)s, %(org_url)s, %(s3_text_url)s, %(s3_images_url)s);
        """
        cursor.execute(query, job_post)
        connection.commit()

    except Exception as e:
        print(f"âŒ ë°ì´í„° ì‚½ì… ì‹¤íŒ¨ (job_post: {job_post.get('org_url')}): {str(e)}")
    finally:
        driver.quit()
    
# ì´ ì•ˆì—ì„œ S3 method import í”¼ì¼ë³´ë‚´ê³  url ë°˜í™˜ / db method ë©”íƒ€ë°ì´í„° ë³´ë‚´ê³  urlë„ ì…ë ¥
# for loop ë§ˆë‹¤ dbë¡œ ë³´ë‚´ë©´ ì¤‘ê°„
def process_contents(div_selectors, s3_text_path, s3_image_path):
    """
    ì§€ì •ëœ CSS Selectorsì—ì„œ í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ íƒì§€í•˜ì—¬ ìµœì¢… notice_type ê°’ì„ ë°˜í™˜í•˜ê³ ,
    íƒì§€ëœ ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ ë””ë ‰í† ë¦¬ì— ë‹¤ìš´ë¡œë“œí•˜ë©° í…ìŠ¤íŠ¸ëŠ” í•˜ë‚˜ë¡œ ë¬¶ì–´ ë¡œì»¬ì— ì €ì¥.
    """
    all_image_urls = []  # ëª¨ë“  ì„¹ì…˜ì˜ ì´ë¯¸ì§€ URL ì €ì¥
    all_texts = []  # ëª¨ë“  ì„¹ì…˜ì˜ í…ìŠ¤íŠ¸ ì €ì¥
    final_notice_type = "none"  # ì´ˆê¸°ê°’ ì„¤ì •

    for selector in div_selectors:
        try:
            # ì„¹ì…˜ ê°€ì ¸ì˜¤ê¸°
            section = driver.find_element(By.CSS_SELECTOR, selector)

            # í…ìŠ¤íŠ¸ íƒì§€
            section_text = section.text.strip() if section.text else None
            if section_text:
                all_texts.append(section_text)

            # ì´ë¯¸ì§€ íƒì§€
            image_elements = section.find_elements(By.TAG_NAME, "img")
            section_image_urls = [img.get_attribute("src") for img in image_elements if img.get_attribute("src")]
            all_image_urls.extend(section_image_urls)
            
            # notice_type ì—…ë°ì´íŠ¸
            if section_text and section_image_urls:
                final_notice_type = "both"
            elif section_text and final_notice_type != "both":
                final_notice_type = "text"
            elif section_image_urls and final_notice_type not in ["both", "text"]:
                final_notice_type = "image"
        except Exception as e:
            print(f"CSS Selector {selector} ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

    # í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
    combined_text = "\n".join(all_texts)
    uploaded_text_path = upload_text_to_s3(s3_text_path, combined_text)

    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    uploaded_image_paths = upload_image_to_s3(s3_image_path, all_image_urls)

    return final_notice_type, uploaded_image_paths, uploaded_text_path

def upload_text_to_s3(s3_text_path, texts):
    """ í…ìŠ¤íŠ¸ë¥¼ S3ì— ì—…ë¡œë“œí•˜ê³  URLì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ """
    text_uuid = str(uuid.uuid4())  # UUID ìƒì„±
    text_key = f"{s3_text_path}{text_uuid}.txt"  # S3ì— ì €ì¥í•  ê²½ë¡œ ë° íŒŒì¼ëª…
    try:
        s3.put_object(Bucket=BUCKET_NAME, Key=text_key, Body=texts)
        text_url = f"s3://{BUCKET_NAME}/{text_key}"
        print(f"âœ… íŒŒì¼ {text_key}ê°€ ì„±ê³µì ìœ¼ë¡œ S3 {text_url}ì— ì—…ë°ì´íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤")
        return text_url
    except Exception as e:
        print(f"â›” [ERROR] Failed to upload text to S3: {e}")
        return None

def upload_image_to_s3(s3_image_path, image_urls):
    """ ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì´ë¯¸ì§€ë¥¼ S3ì— ì—…ë¡œë“œí•˜ê³  S3 URL ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ """
    s3_urls = []  # ì—…ë¡œë“œëœ S3 URLì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for image_url in image_urls:
        try:
            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            response = requests.get(image_url, stream=True)
            response.raise_for_status()  # ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ
            # UUIDë¡œ ê³ ìœ  ì´ë¦„ ìƒì„±
            image_uuid = str(uuid.uuid4())
            image_key = f"{s3_image_path}{image_uuid}.jpg"
            # S3ì— ì—…ë¡œë“œ
            s3.upload_fileobj(response.raw, BUCKET_NAME, image_key)
            # ì—…ë¡œë“œëœ S3 URL ìƒì„±
            s3_url = f"s3://{BUCKET_NAME}/{image_key}"
            s3_urls.append(s3_url)

        except Exception as e:
            print(f"â›” [ERROR] ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨ ({image_url}): {e}")

    # ì½¤ë§ˆë¡œ ì—°ê²°ëœ S3 URL ë°˜í™˜
    print(f"âœ… ì´ë¯¸ì§€ íŒŒì¼(ë“¤)ì´ ì„±ê³µì ìœ¼ë¡œ S3 {s3_image_path}ì— ì—…ë°ì´íŠ¸ ë˜ì—ˆìŠµë‹ˆë‹¤")
    return s3_urls

def get_latest_txt_files(s3_link_path):
    # ëª¨ë“  íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ContinuationToken í™œìš©)
    files = []
    continuation_token = None
    while True:
        params = {'Bucket': BUCKET_NAME, 'Prefix': s3_link_path}
        if continuation_token:
            params['ContinuationToken'] = continuation_token
        response = s3.list_objects_v2(**params)

        # s3 path ì— íŒŒì¼ì´ ì•„ì˜ˆ ì—†ì„ ê²½ìš° ì²˜ë¦¬
        if 'Contents' not in response:
            print(f"[ERROR] í•´ë‹¹ S3 pathì— íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {s3_link_path}")
            return None
        # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        files.extend(response['Contents'])

        # ë‹¤ìŒ í˜ì´ì§€ë¡œ ë„˜ì–´ê°ˆ ContinuationToken í™•ì¸
        continuation_token = response.get('NextContinuationToken')
        if not continuation_token:
            break
    
    # txt íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    txt_files = [content['Key'] for content in files if content['Key'].endswith('.txt')]
    if not txt_files:
        print("No .txt files found in the specified directory.")
        return []
    
    # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ í›„ ì •ë ¬
    txt_files.sort(key=lambda x: datetime.strptime(x.split('/')[-1].split('.')[0], '%Y%m%d'))
    # ìµœì‹  íŒŒì¼ 1ê°œ ë˜ëŠ” 2ê°œ ê°€ì ¸ì˜¤ê¸°
    latest_files = txt_files[-2:] if len(txt_files) > 1 else txt_files
    # ìµœì‹  íŒŒì¼ 2ê°œì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    file_contents = []
    for file_key in latest_files:
        try:
            obj = s3.get_object(Bucket=BUCKET_NAME, Key=file_key)
            file_content = obj['Body'].read().decode('utf-8')
            file_contents.append(file_content)
        except Exception as e:
            print(f"[ERROR] íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í‚¤: {file_key}, ì—ëŸ¬: {e}")
    return file_contents

def update_removed_links_in_db(removed_links, connection):
    try:
        if not connection.open:
            connection.ping(reconnect=True)  # ì—°ê²°ì´ ë‹«í˜€ìˆë‹¤ë©´ ì¬ì—°ê²° ì‹œë„
        for link in removed_links:
            sql = """
            UPDATE airflowT SET removed_time = %s WHERE org_url = %s
            """
            cursor.execute(sql, (datetime.today().strftime("%Y-%m-%d"), link))
        connection.commit()
        print(f"Updated removed links in DB: {len(removed_links)}")
    except Exception as e:
        print(f"Error updating removed links in DB: {e}")

# ë©”ì¸ ë©”ì†Œë“œ
def main():
    try:
        if not connection.open:
            print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        for job_abb, job_title in job_titles.items():
            s3_link_path = S3_LINK_PATH.format(abb = job_abb)
            s3_text_path = S3_TEXT_PATH.format(abb = job_abb) # s3 í…ìŠ¤íŠ¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
            s3_image_path = S3_IMAGE_PATH.format(abb = job_abb) # s3 ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ ì„¤ì •

            # s3ì•ˆì— ì–´ì œ ì˜¤ëŠ˜ ë§í¬ ê°€ì§€ê³  ì˜¤ê¸°
            latest_contents = get_latest_txt_files(s3_link_path)
            if len(latest_contents) == 0:
                print(f"{job_title}: You need to crawl the links first")

            elif len(latest_contents) == 1:
                # s3ì— ì˜¤ëŠ˜ í¬ë¡¤ë§í•œ ë¦¬ìŠ¤íŠ¸ë§Œ ìˆì„ë•Œ
                today_list = latest_contents[0].splitlines()
                for url in today_list:
                    get_job_posts(url, job_title, s3_text_path, s3_image_path)
                print(f"[CHECKING] ì˜¤ëŠ˜ í¬ë¡¤ë§í•œ ê³µê³ ì˜ ê°œìˆ˜: {len(today_list)}ê°œ")
            elif len(latest_contents) == 2:
                # "url1\nurl2\nurl3" í˜•ì‹ìœ¼ë¡œ ë‚˜ì˜¤ë¯€ë¡œ listë¡œ ë³€í™˜
                yesterday_list = latest_contents[0].splitlines()
                today_list = latest_contents[-1].splitlines()
                print(f"{job_title}: {s3_link_path}ë¡œë¶€í„° ì˜¤ëŠ˜ê³µê³  {len(today_list)}ê°œ, ì–´ì œ ê³µê³  {len(yesterday_list)}ê°œ")

                # today_listì—ëŠ” ìˆì§€ë§Œ yesterday_listì—ëŠ” ì—†ëŠ” URL ë¦¬ìŠ¤íŠ¸
                only_in_today = list(set(today_list) - set(yesterday_list))
                for url in only_in_today:
                    get_job_posts(url, job_title, s3_text_path, s3_image_path)
                print(f"[CHECKING] ì˜¤ëŠ˜ í¬ë¡¤ë§í•œ ê³µê³ ì˜ ê°œìˆ˜: {len(only_in_today)}ê°œ")

                # yesterday_listì—ëŠ” ìˆì§€ë§Œ today_listì—ëŠ” ì—†ëŠ” URL ë¦¬ìŠ¤íŠ¸
                only_in_yesterday = list(set(yesterday_list) - set(today_list))
                update_removed_links_in_db(only_in_yesterday, connection)
            else:
                # ì´ë¡ ì ìœ¼ë¡œëŠ” len(latest_contents)ê°€ 0, 1, 2 ì´ì™¸ì˜ ê°’ì„ ê°€ì§ˆ ìˆ˜ ì—†ìŒ
                print(f"{job_title}: Unexpected number of files found.")
            
            # ê·¸ë¦¬ê³  ì €ì¥ëœ path jsonìœ¼ë¡œ ë°›ì•„ì™€ì„œ dbì— ì „ë¶€ ì—…ë°ì´íŠ¸ - dbmethod
            print(f"ğŸŒŸ{job_title}ì— ëŒ€í•œ í¬ë¡¤ë§ê³¼ DBì—…ë°ì´íŠ¸ë¥¼ ì™„ë£Œí•˜ì˜€ìŠµë‹ˆë‹¤!")

        print("âœ… ëª¨ë“  ë°ì´í„° ì‚½ì… ë° ì—…ë°ì´íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!")
    except Exception as e:
        print(f"Unexpected error during main execution: {e}")
    finally:
        driver.quit()
        cursor.close()
        connection.close()


if __name__=="__main__":
    main()