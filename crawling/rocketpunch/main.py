from rocketpunch_crawling import get_job_posts
from rocketpunch_links import get_all_links
from s3_methods import get_yesterday_links, save_link_to_s3
from db_methods import update_deleted_links, update_content, unique_url
from datetime import datetime as dt
from zoneinfo import ZoneInfo
import logging

# ë¡œê¹… ì„¤ì •
# logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
# logger = logging.getLogger(__name__)

# Variable declaration
kst = ZoneInfo("Asia/Seoul")

BUCKET_NAME = 't2jt'
S3_LINK_PATH = 'job/{abb}/sources/rocketpunch/links/'
S3_TEXT_PATH = 'job/{abb}/sources/rocketpunch/txt/'
S3_IMAGE_PATH = 'job/{abb}/sources/rocketpunch/images/'  # ë””ë ‰í† ë¦¬ ê²½ë¡œì— í•´ë‹¹

# rl, rc ëª¨ë“ˆë‚´ì— ì“°ì¼ driverë¡œ ë„˜ê²¨ì¤„ ê²ƒ
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.110 Safari/537.36'}

# job_titles = {
#     "DE":"ë°ì´í„° ì—”ì§€ë‹ˆì–´", 
#     "DA":"ë°ì´í„° ë¶„ì„ê°€", 
#     "FE":"í”„ë¡ íŠ¸ì—”ë“œ ì—”ì§€ë‹ˆì–´", 
#     "BE":"ë°±ì—”ë“œ ì—”ì§€ë‹ˆì–´", 
#     "MLE":"ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´"
#     }
job_titles = {"DE":"ë°ì´í„° ì—”ì§€ë‹ˆì–´"}

def main():
    
    unique_url() # db org_url unique ë¶€ì—¬

    # ê° job_title ë§ˆë‹¤ urlê³¼ s3 directory assign í•˜ê¸°
    for job_abb, job_title in job_titles.items():

        # s3 ê²½ë¡œ ì„¤ì •
        s3_link_path = S3_LINK_PATH.format(abb = job_abb)
        # s3ì•ˆì— ì–´ì œ ë§í¬ ê°€ì§€ê³  ì˜¤ê¸°
        latest_links = get_yesterday_links(BUCKET_NAME, s3_link_path)
        print(f"[CHECKING] S3ì—ì„œ ë°›ì•„ì˜¨ ìµœì‹  ê³µê³  ë¦¬ìŠ¤íŠ¸ ê¸¸ì´: {len(latest_links)}")
        # s3í•´ë‹¹ ë””ë ‰í† ë¦¬ì•ˆì— txtì—†ìœ¼ë©´ ì˜¤ëŠ˜ì ë§í¬ ìˆ˜ì§‘ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° 
        if latest_links is None:
            print(f"{s3_link_path}ì— ë§í¬ txt íŒŒì¼ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë¯€ë¡œ ì˜¤ëŠ˜ì ê³µê³  ë§í¬ í¬ë¡¤ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        
        # ì˜¤ëŠ˜ì ë§í¬ ìˆ˜ì§‘ ì§„í–‰
        today_links = get_all_links(job_title)
        today_date = dt.now(tz=kst).strftime('%Y%m%d')

        # ì¼ë‹¨ ì˜¤ëŠ˜ ìˆ˜ì§‘í•œê±° íŒŒì¼ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ s3ì— ì €ì¥
        save_link_to_s3(BUCKET_NAME, s3_link_path, today_date, today_links)

        # ì–´ì œ ë¦¬ìŠ¤íŠ¸(latest_links) ì™€ ì˜¤ëŠ˜ ë¦¬ìŠ¤íŠ¸(today_links) ë¹„êµ
        
        # 1. ì œê±°ëœ ê³µê³  dbì— removed time ì—…ë°ì´íŠ¸ ë³´ë‚´ê¸° - s3m ëª¨ë“ˆ ì‚¬ìš©?
        links_removed = [link for link in latest_links if not today_links or link not in today_links]
        update_deleted_links(links_removed)
        # 2. ì¶”ê°€ëœ ê³µê³ ì— ëŒ€í•˜ì—¬ rc ëª¨ë“ˆì‚¬ìš© ìƒì„¸ ê³µê³  í¬ë¡¤ë§ ì§„í–‰ - ë©”íƒ€ë°ì´í„° dbë¡œ ë°”ë¡œ
        links_added = [link for link in today_links if not latest_links or link not in latest_links]

        # links_added í¬ë¡¤ë§ ì§„í–‰ - í•˜ë‚˜ í¬ë¡¤ë§í• ë•Œë§ˆë‹¤ ë°”ë¡œ s3 ì „ì†¡
        job_posts = get_job_posts(BUCKET_NAME, links_added, S3_TEXT_PATH, S3_IMAGE_PATH)
        print(f"[CHECKING] job_posts ê°€ ì˜ ì…ë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ lengthë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤: {len(job_posts)}ê°œ")
        # ê·¸ë¦¬ê³  ì €ì¥ëœ path jsonìœ¼ë¡œ ë°›ì•„ì™€ì„œ dbì— ì „ë¶€ ì—…ë°ì´íŠ¸ - dbmethods
        update_content(job_posts)

        print(f"ğŸŒŸ{job_title}ì— ëŒ€í•œ í¬ë¡¤ë§ê³¼ DBì—…ë°ì´íŠ¸ë¥¼ ì™„ë£Œí•˜ì˜€ìŠµë‹ˆë‹¤!")
        
if __name__=="__main__":
    main()

# ì¶”ê°€ë¡œ ê³ ë ¤í•´ì•¼í•  ì‚¬í•­ 1. logì–´ë–»ê²Œ